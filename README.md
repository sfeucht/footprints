# Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs
https://footprints.baulab.info


## Code
Describe all the code 

## Data
We use three datasets in this paper. 

- CounterFact:
    - expanded1_text (rename) used for all of the CounterFact tests in the paper
- Pile:
    - train_tiny_1000.csv 'text' column used to train probes
    - val_tiny_500.csv used to validate probe hparams
    - test_tiny_500.csv used for overall Pile test results
- Wikipedia:
    - wikipedia_val_500.csv (rename) used for overall Wikipedia test results
    - wikipedia_test_500 and wikipedia_train_1000.csv untouched, kept for posterity
